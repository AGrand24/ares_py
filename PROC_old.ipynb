{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9bbf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from ares_py.class_project import Project\n",
    "from ares_py.tools.get_ld import get_ld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdf2e8",
   "metadata": {},
   "source": [
    "projects\n",
    "* name\n",
    "    * 00_doc\n",
    "    * 01_2dm\n",
    "    * 02_crd\n",
    "    * 03_qcl\n",
    "    * 04_inv\n",
    "    * 05_grd\n",
    "    * 06_mod\n",
    "    * 99_qgs\n",
    "        * name_rec.gpkg\n",
    "            * rec_ert_pt - recorded coordinates in field -ert\n",
    "            * rec_gen_pt - recorded coordinates - general\n",
    "        * name_spatial.gpkg\n",
    "            * crd_plan_ls, crd_plan_pt\n",
    "            * crd_man_input_pt, crd_man_proc_pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d742ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"kysuce\"\n",
    "\n",
    "grid_skip = [1, 2, 3, 4, 5, 6]\n",
    "crs = 8353\n",
    "res_range = [1, 1000]\n",
    "\n",
    "\n",
    "atlas_input = dict(\n",
    "    res_min=[0] * 6,\n",
    "    res_max=[500] * 6,\n",
    "    page_heights=[420] * 6,\n",
    "    map_scales=[500] * 6,\n",
    "    lvl_frequency=6 * [3],\n",
    "    z_gap=[20, 15, 15, 25, 25, 25],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2580f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"budmerice\"\n",
    "\n",
    "grid_skip = [1, 2, 3, 4, 5, 6]\n",
    "crs = 8353\n",
    "res_range = [1, 1000]\n",
    "\n",
    "\n",
    "atlas_input = dict(\n",
    "    res_min=[0] * 6,\n",
    "    res_max=[500] * 6,\n",
    "    page_heights=[420] * 6,\n",
    "    map_scales=[500] * 6,\n",
    "    lvl_frequency=6 * [3],\n",
    "    z_gap=[20, 15, 15, 25, 25, 25],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6fddf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"dd_lavka\"\n",
    "\n",
    "grid_skip = [1, 2, 3, 4, 5]\n",
    "crs = 8353\n",
    "res_range = [1, 10000]\n",
    "\n",
    "\n",
    "atlas_input = dict(\n",
    "    res_min=[100] * 5,\n",
    "    res_max=[20000] * 5,\n",
    "    page_heights=[594, 420, 420, 420, 420],\n",
    "    page_heights_int=[420] + [297] * 4,\n",
    "    map_scales=[1000] * 5,\n",
    "    lvl_frequency=5 * [3],\n",
    "    z_gap=[15, 15, 15, 15, 5],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf8284",
   "metadata": {},
   "source": [
    "**CREATE PROJECT**\n",
    "\n",
    "1. Run init project with project name input -> prj class, creates folder structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526284b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prj = Project(project_name, crs=crs, res_range=res_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c9458",
   "metadata": {},
   "source": [
    "**PROCESS FLAT COORDINATES**\n",
    "\n",
    "1. Run prj.Process_2dm() - with **flat mode coordinates**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db15406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects\\dd_lavka\\01_input\\001.2dm\n",
      "projects\\dd_lavka\\01_input\\002.2dm\n",
      "projects\\dd_lavka\\01_input\\003.2dm\n",
      "projects\\dd_lavka\\01_input\\004.2dm\n",
      "projects\\dd_lavka\\01_input\\005.2dm\n"
     ]
    }
   ],
   "source": [
    "prj = prj.Process_raw(crd_mode=\"flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c502164",
   "metadata": {},
   "source": [
    "**PROCESS - ert_plan_pt**\n",
    "\n",
    "1. Draw planed lines - **ert.gpkg - ert_plan_ls**\n",
    "1. Copy **dtm.tif** into project/qgis folder\n",
    "1. Run model **ert_ls2pt** in QGIS project and save data manually to **./tmp/tmp_plan.gpkg**\n",
    "1. Run prj.Process_crd_plan () -> **input/{line}_plan.csv**, **ert.gpkg - ert_plan_pt**\n",
    "1. Run prj.Process_2dm() -> loads 2dm, adds coordinates from **input/{line}_plan.csv**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980ca5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects\\dd_lavka\\01_input\\001.2dm\n",
      "projects\\dd_lavka\\01_input\\002.2dm\n",
      "projects\\dd_lavka\\01_input\\003.2dm\n",
      "projects\\dd_lavka\\01_input\\004.2dm\n",
      "projects\\dd_lavka\\01_input\\005.2dm\n"
     ]
    }
   ],
   "source": [
    "prj = prj.Process_crd_plan()\n",
    "prj = prj.Process_2dm(crd_mode=\"plan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45311334",
   "metadata": {},
   "source": [
    "**PROCESS rec coordinates**\n",
    "1. Run prj.Process_crd_rec() -> **crd_man_input_pt** *(if not exist)*\n",
    "1. Edit man pt coordinates **ert.gpkg - crd_man_input_pt**\n",
    "1. Run model rec proc_man  and save to  **tmp/tmp_rec.gpkg**  *(interpolated (1m) coordinates from ert.gpkg - crd_man_input_pt, DTM sampled)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d70ea2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rec crd - line 1, 55 entries\n",
      "Processing rec crd - line 2, 13 entries\n",
      "Processing rec crd - line 3, 10 entries\n",
      "Processing rec crd - line 4, 0 entries\n",
      "Processing rec crd - line 5, 3 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamg\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyogrio\\raw.py:198: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D Point' is converted to 'Point Z'\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "prj = prj.Process_crd_rec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a3f20d",
   "metadata": {},
   "source": [
    "**PROCESS man coordinates**\n",
    "1. Run prj.Process_crd_man() -> **crd_man_proc_pt** *(coordinates with recalculated ld)*, **input/{line}_man.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c087c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamg\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyogrio\\core.py:130: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D Point' is converted to 'Point Z'\n",
      "  return ogr_list_layers(get_vsi_path_or_buffer(path_or_buffer))\n"
     ]
    }
   ],
   "source": [
    "prj = prj.Process_crd_man()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f91b4",
   "metadata": {},
   "source": [
    "**PROCESS 2dm**\n",
    "\n",
    "1. Set coordinates mode to select coordinates type from csv file:\n",
    "    + *plan - original planned coordinates*\n",
    "    + *rec - recorded in field*\n",
    "    + *man - manual coordinates*\n",
    "1. Run prj.Process_2dm() -> loads 2dm, adds coordinates from **input/{line}_man.csv**\n",
    "1. Run prj.Proc_topo_2d() -> exports topo to **ert.gpkg -ert2d_topo_pt, ert2d_topo_ls**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f27c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects\\dd_lavka\\01_input\\001.2dm\n",
      "projects\\dd_lavka\\01_input\\002.2dm\n",
      "projects\\dd_lavka\\01_input\\003.2dm\n",
      "projects\\dd_lavka\\01_input\\004.2dm\n",
      "projects\\dd_lavka\\01_input\\005.2dm\n"
     ]
    }
   ],
   "source": [
    "prj = prj.Process_2dm(crd_mode=\"man\")\n",
    "prj = prj.Proc_topo_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bdd89e",
   "metadata": {},
   "source": [
    "**Grid data and process contours**\n",
    "1. Grid grd inputs manually or run prj.Grid_data() to grid and export surfer grids \n",
    "    * enter skip list to ignore lines (eg. for long lines)\n",
    "    * runs gridding on all .csv files in **04_grd/** (except skipped lines)\n",
    "    * -> **04_grd/{line}_{input_name}.grd\n",
    "\n",
    "1. Run prj.Export_contours()\n",
    "    + process contours for all files in **04_grd/** folder\n",
    "    + -> **ert.gpkg - grd_contours_{type}_ls**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b858913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting contours - projects\\dd_lavka\\04_grd\\001_r2d.grd\n",
      "Error exporting contours..\n",
      "Exporting contours - projects\\dd_lavka\\04_grd\\002_r2d.grd\n",
      "Error exporting contours..\n",
      "Exporting contours - projects\\dd_lavka\\04_grd\\003_r2d.grd\n",
      "Error exporting contours..\n",
      "Exporting contours - projects\\dd_lavka\\04_grd\\004_r2d.grd\n",
      "Error exporting contours..\n",
      "Exporting contours - projects\\dd_lavka\\04_grd\\005_r2d.grd\n",
      "Error exporting contours..\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# prj = prj.Grid_data(skip=[grid_skip], cell_size=1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m prj = \u001b[43mprj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExport_contours\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adamg\\OneDrive\\01_Processing\\ares_py\\ares_py\\class_project.py:535\u001b[39m, in \u001b[36mProject.Export_contours\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    532\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    533\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mError exporting contours..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     cnt = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnt\u001b[49m\u001b[43m)\u001b[49m.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    536\u001b[39m     cnt.to_file(\u001b[38;5;28mself\u001b[39m.fps[\u001b[33m\"\u001b[39m\u001b[33mert\u001b[39m\u001b[33m\"\u001b[39m], layer=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgrd_contours_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_ls\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adamg\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adamg\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adamg\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# prj = prj.Grid_data(skip=[grid_skip], cell_size=1)\n",
    "prj = prj.Export_contours()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842d06a",
   "metadata": {},
   "source": [
    "**Process inversion outputs**\n",
    "1. Do the inversions - export data to **inv/** folder formats:\n",
    "    + zond - _znd.dat\n",
    "    + r2d - _topres.dat\n",
    "\n",
    "1. Run prj.Export_gridding_input() - reads and formats inversion outputs -> **04_grd/{line}.csv**\n",
    "2. Run prj.Export_gpkg_inv() - exports inversion points to -> **ert.gpkg - inv_{type}_pt**\n",
    "    + type = r2d / znd\n",
    "1. Run prj.Export_mask()->  **ert.gpkg - mask_pl**\n",
    "1. Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad667358",
   "metadata": {},
   "outputs": [],
   "source": [
    "prj = prj.Export_gridding_input()\n",
    "\n",
    "prj = prj.Export_gpkg_inv()\n",
    "prj = prj.Export_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc862a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c526ccc",
   "metadata": {},
   "source": [
    "**Generate atlas_qc:**\n",
    "1. Enter atlas input: \n",
    "    + *res_range_qc - res_min and res_max for qc graphs in Ohmm*\n",
    "    + *page heights*\n",
    "    + *map scales*\n",
    "    + *lvl_frequency = layer frequency for qc graphs 1= all, 2= every 2nd...*\n",
    "    + *z_gap = offset from top wof atlas extent for grid maps in meters*\n",
    "1. Run prj.Atlas_qc() -> **ert.gpkg - atlas_qc**\n",
    "1. Run prj.QC_lines() -> **qgis/{line}.png, qgis/{line}.pgw,** \n",
    "1. Run prj.Export_surface_notes()\n",
    "    + *surface notes polygon on top of atlas window*\n",
    "    + -> **ert.gpkg - notes_surface_pl** \n",
    "    + creates **notes_surface_man_pl* if not exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "prj = prj.Atlas_qc(atlas_input)\n",
    "prj = prj.QC_lines()\n",
    "prj = prj.Export_surface_notes()\n",
    "pd.DataFrame(prj.atlas_qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd459e",
   "metadata": {},
   "source": [
    "**EXPORT MODEL TEMPLATE**\n",
    "\n",
    "1. Run prj.Export_model_template() -> splits mask multipolygon to separate polygons **ert.gpkg - 03_model_pl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e59c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "prj = prj.Export_model_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5daf212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "data = prj.ert[\"001\"].data\n",
    "\n",
    "electrodes = pd.DataFrame(data[[\"c1\", \"c2\", \"p1\", \"p2\", \"ID_meas\"]])\n",
    "electrodes = electrodes.set_index(\"ID_meas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee147905",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = gpd.read_file(prj.fps[\"ert\"], layer=\"crd_man_proc_pt\")\n",
    "topo = topo.loc[topo[\"ID_line\"] == 1].set_index(\"ld\")\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for col in electrodes.columns:\n",
    "    x.append(\n",
    "        pd.merge(electrodes[col], topo[\"x\"], \"left\", left_on=col, right_index=True)[\n",
    "            \"x\"\n",
    "        ].values\n",
    "    )\n",
    "    y.append(\n",
    "        pd.merge(electrodes[col], topo[\"y\"], \"left\", left_on=col, right_index=True)[\n",
    "            \"y\"\n",
    "        ].values\n",
    "    )\n",
    "    z.append(\n",
    "        pd.merge(electrodes[col], topo[\"z0\"], \"left\", left_on=col, right_index=True)[\n",
    "            \"z0\"\n",
    "        ].values\n",
    "    )\n",
    "\n",
    "xx = np.column_stack(x)\n",
    "yy = np.column_stack(y)\n",
    "zz = np.column_stack(z)\n",
    "\n",
    "r1 = (0, 2)\n",
    "r2 = (1, 2)\n",
    "r3 = (0, 3)\n",
    "r4 = (1, 3)\n",
    "\n",
    "dist = []\n",
    "for c in [r1, r2, r3, r4]:\n",
    "    dx = (xx[:, c[0]] - xx[:, c[1]]) ** 2\n",
    "    dy = (yy[:, c[0]] - yy[:, c[1]]) ** 2\n",
    "    dz = (zz[:, c[0]] - zz[:, c[1]]) ** 2\n",
    "    dist.append((dx + dy) ** 0.5)\n",
    "    # dist.append((dx + dy + dz) ** 0.5)\n",
    "\n",
    "dist = np.column_stack(dist)\n",
    "dist = 1 / dist\n",
    "k = 2 * np.pi / (dist[:, 0] - dist[:, 1] - dist[:, 2] + dist[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"r\"] = data[\"v\"] / data[\"i\"]\n",
    "data[\"res2\"] = data[\"r\"] * data[\"k2\"]\n",
    "diff = np.clip(data[\"res\"] - data[\"res2\"], -10000, 10000)\n",
    "data.plot.scatter(data[\"ld\"], diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b562a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"k\"] = np.pi * data[\"n\"] * (data[\"n\"] + 1) * data[\"a\"]\n",
    "data[\"k\"] = data[\"k\"].round()\n",
    "data.plot.scatter(data[\"ld\"], y=data[\"k2\"] - data[\"k\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ab8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ares_py.qc_lines import fig_qc_lines\n",
    "\n",
    "\n",
    "def get_levels(df, lvl_frequency):\n",
    "    df[\"lab\"] = \"z= \" + np.abs(np.round(df[\"doi\"])).astype(int).astype(str).str.zfill(2)\n",
    "    cols = [\"ld_hor\", \"res2\", \"lab\"]\n",
    "    levels = df.groupby(\"doi\")[cols].apply(np.array).to_list()\n",
    "    levels = levels[::lvl_frequency]\n",
    "    return levels\n",
    "\n",
    "\n",
    "lvls = get_levels(data, 3)\n",
    "\n",
    "ad = prj.atlas_qc.copy().loc[1, :]\n",
    "\n",
    "fig_qc_lines(prj, lvls, ad, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"projects/dd_lavka/03_inversion/001_znd_elc.txt\", sep=\"  \", header=None\n",
    ")\n",
    "df.columns = [\"x\", \"z0\"]\n",
    "geom = gpd.points_from_xy(df.iloc[:, 0] + 10000, df.iloc[:, 1])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geom, crs=8353)\n",
    "gdf.to_file(\"tmp/topo_test.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba18635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"projects/dd_lavka/02_coordinates/001_man.csv\")\n",
    "df = df.loc[df[\"ld\"] % 5 == 0]\n",
    "df.to_csv(\"tmp/topo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5495b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\adamg\\OneDrive\\01_Processing\\ares_py\\tmp\\dtm_mos.csv\", header=None\n",
    ")\n",
    "df.columns = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "df = df.loc[df[\"z\"] != 3.4e38]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
